# ABTest-系统设计

在上一篇文章，我们已经对ABTest系统进行了比较详细的拆解。

![](https://gitee.com/lidaming/assets/raw/master/abtest/ab_flow2.jfif)

ABTest是对流量进行分块对比的方案效果，辅助决策的系统。这里的流量到底在描述什么？如何利用利用对效果进行对比呢？

著名的豌豆实验，大家都知道，通过对比，发现遗传规律。所以实验过程中使用对比是常见的方案。ABTest相当于在助力业务的时候，提供了基础环境。

在这里聊的对流量分组，流量指的是UV不是PV。就是说是面向“用户”进行分组的。

> 为什么是面向用户呢？这里是处于对同一个用户访问同一个页面的时候，是固定样式的，角度出发考虑的。
>
> 如果可以接受，不用两次访问，展现的页面是不同的，可以针对PV的流量进行分组，展开试验。

![](https://gitee.com/lidaming/assets/raw/master/chaju.jpg)

这里思考下：针对UV和PV的流量进行分组的话，产生的影响会是什么？

UV：在针对人进行分组的时候，一个人在进行到实验的时候，所进入到的实验是固定的

PV：任何一个请求都是独立的个体

在实现细节上是有差异的，并且在产生最终的数据的分析结果上，可能也是有差异的。在使用PV进行分组的话，如果有一批人的的流量都分到了某一个分组，这几个人的偏好是相同的，如果这几个人产生了很高的流量，会提升这个分组的转化率，影响分析结果。

## 基础逻辑

无论是针对任何场景，最终是要把用户分入某一个实验的分组。用户可以理解为一个标识（甚至不一定是一个人，只是一个具有标识的对象）。对用户分组原理如图：

![](https://gitee.com/lidaming/assets/raw/master/abtest/group.jpg)

图中表达了完整的用户和实验以及分组的映射逻辑。

所有用户会被分到固定数量的桶中，桶的数量可以根据用户的量级，以及实验精度进行调整变更。图中示例为1000个桶。

这1000个桶和不同的实验的分组，有不同的映射关系。如Experiment1 的实验分组：红、蓝、灰；不同的组根据流量比例，对应有不同的桶。

用户请求进来的时候，读取用户标识经过hash以后，可以映射到特定桶。接着可以确定用户需要参加的真实的实验分组。

> 注：hash函数设计好之后，需要对hash函数进行规模测试，确保不会有倾斜



## 体系设计

一套AB实验系统，不只是简单单的对用户分组就结束了，完成对用户的公平分组，只是开始。中间需要有数据采集，数据分析，结果呈现。整体架构如图：

![](https://gitee.com/lidaming/assets/raw/master/abtest/ABTest%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png)

可以看到各个端的流量最终都会落到AB测试平台，还会将产生分分组数据，上报给AB平台的数据收集器。

数据分析平台结合业务数据，完整整个实验效果的分析。产出不同的方案下，的不同转化率，产出最佳实验方案。



## 架构优化

随着业务的增长，流量也在不断增长。并且随着平台的稳定，实验量也是不断增加的。流量增加到一定量级后，如果对整个体系进行优化呢。

增加AB实验的服务节点，可以解决，只不过是暴力的横向扩展而已。怎么从软件层面进行架构升级呢？

在实验量级达到一定程度以后，缓存怎么设计呢？缓存能抗住流量吗？



可以通过客户端负载来实现，负载均衡，满足流量激增的场景。升级后的架构如图：

![](https://gitee.com/lidaming/assets/raw/master/abtest/ABTest%E5%8D%87%E7%BA%A7%E6%9E%B6%E6%9E%84.png)

整体架构是依靠zk作为 整个集群协调的。AB Server 的Group是根据不同的试验进行进行hash后，进入不同的存储目录，不同Group下的server只会加载自己Group下的实验，这样解决了实验量级增加的问题。

进行不同的Group区分后，在客户端的SDK中启动后优先获读取实验分布的节点信息，然后在客户端进行负载。

## 继续优化

为什么还要优化？因为流量在增长，业务在变化。

实验对分组的分布，可以考虑采用一致性哈希，来解决分布问题。

在业务规模扩充了，可以考虑分机房部署，就近路由（交给客户端sdk）的方法解决。
